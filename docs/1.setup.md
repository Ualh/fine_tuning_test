# Setup (Docker, environment, tokens)

This project runs fully locally using Docker. Follow these steps once to get ready.

## Prerequisites
- Windows with PowerShell
- Docker Desktop installed and running
- (Optional, GPU) Recent NVIDIA driver + CUDA toolkit installed on host
- A Hugging Face token if the base model/datasets are gated

## One-time setup
1) Create a `.env` file (for HF access):

```
HF_TOKEN=hf_XXXXXXXXXXXXXXXXXXXXXXXX
```

2) Build the training image and start the container:

```powershell
.\run_pipeline.bat build
.\run_pipeline.bat up
```

This brings up the training service `qwen25-05b` in CPU mode by default.

## GPU notes (optional)
- To enable GPU for training, open `docker-compose.yml` and:
  - Uncomment `# gpus: all` under the `qwen25-05b` service.
  - Ensure Docker Desktop has GPU support enabled.
- The included vLLM server is configured to run on CPU by default. You can switch it to GPU by setting `VLLM_TARGET_DEVICE=cuda` and ensuring the container has access to the GPU.

## SSL and enterprise proxies
The pipeline disables SSL verification for Hugging Face downloads to work in restricted networks. This is handled by:
- Environment variables in `docker-compose.yml`
- A runtime helper (`disable_ssl_verification()`) inside the code

If you donâ€™t need this, you can remove those toggles later.

## Start/stop containers
```powershell
.\run_pipeline.bat up     # start training container
.\run_pipeline.bat down   # stop all containers
.\run_pipeline.bat bash   # shell inside the container
```